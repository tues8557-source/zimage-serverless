import runpod
import torch
from diffusers import AutoPipelineForText2Image
import io
import base64
import os

# 1. ëª¨ë¸ ì„¤ì • (GPU ë©”ëª¨ë¦¬ì— ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ)
MODEL_ID = "stabilityai/sdxl-turbo"
pipe = AutoPipelineForText2Image.from_pretrained(
    MODEL_ID, 
    torch_dtype=torch.float16, 
    variant="fp16"
).to("cuda")

def handler(event):
    inp = event.get("input", {})
    action = inp.get("action", "generate") # ê¸°ë³¸ê°’ì€ ìƒì„± ëª¨ë“œ

    # ğŸ”¹ [ê¸°ëŠ¥ 1] ë¡œë¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ìš”ì²­ ì²˜ë¦¬
    if action == "list_loras":
        lora_dir = "/loras"
        if os.path.exists(lora_dir):
            files = [f for f in os.listdir(lora_dir) if f.endswith('.safetensors')]
            return {"lora_list": sorted(files)}
        else:
            return {"lora_list": [], "error": "Folder not found"}
            
    # ğŸ”¹ [ê¸°ëŠ¥ 2] ì´ë¯¸ì§€ ìƒì„± ë¡œì§
    prompt = inp.get("prompt", "")
    lora_name = inp.get("lora_name", None)
    
    # "none" ë¬¸ìì—´ ì²˜ë¦¬
    if lora_name == "none":
        lora_name = None
        
    lora_scale = float(inp.get("lora_scale", 1.0))
    width = int(inp.get("width", 512))
    height = int(inp.get("height", 512))
    steps = int(inp.get("steps", 4))

    # ë¡œë¼ ë™ì  ë¡œë“œ/í•´ì œ
    if lora_name:
        lora_path = f"/loras/{lora_name}"
        if os.path.exists(lora_path):
            try:
                pipe.unload_lora_weights() # ì´ì „ ë¡œë¼ ì œê±°
                pipe.load_lora_weights(lora_path)
                print(f"DEBUG: [LoRA ì„±ê³µ] '{lora_name}' ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"DEBUG: [LoRA ì‹¤íŒ¨] ì—ëŸ¬: {e}")
                lora_name = None
        else:
            print(f"DEBUG: [LoRA ì‹¤íŒ¨] íŒŒì¼ ì—†ìŒ: {lora_path}")
            lora_name = None
    else:
        pipe.unload_lora_weights()
        print("DEBUG: ê¸°ë³¸ ëª¨ë¸ ëª¨ë“œ")

    # ì´ë¯¸ì§€ ìƒì„± ì‹œì‘
    try:
        with torch.inference_mode():
            image = pipe(
                prompt=prompt,
                num_inference_steps=steps,
                guidance_scale=0.0,
                width=width,
                height=height,
                cross_attention_kwargs={"scale": lora_scale} if lora_name else {}
            ).images[0]

        # ì´ë¯¸ì§€ ë°˜í™˜
        buf = io.BytesIO()
        image.save(buf, format="PNG")
        return {"image": base64.b64encode(buf.getvalue()).decode("utf-8")}

    except Exception as e:
        return {"error": str(e)}

# ì„œë²„ë¦¬ìŠ¤ ì‹œì‘
runpod.serverless.start({"handler": handler})
