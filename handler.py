import runpod
import torch
from diffusers import AutoPipelineForText2Image
import io
import base64
import os  # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©

# 1. ëª¨ë¸ ì„¤ì • (ë¡œë¼ëŠ” ì—¬ê¸°ì„œ ë¯¸ë¦¬ ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)
MODEL_ID = "stabilityai/sdxl-turbo"
pipe = AutoPipelineForText2Image.from_pretrained(
    MODEL_ID, torch_dtype=torch.float16, variant="fp16"
).to("cuda")

def handler(event):
    inp = event.get("input", {})
    
    # ğŸ”¹ ComfyUIì—ì„œ ë„˜ê²¨ì¤„ ê°’ë“¤
    prompt = inp.get("prompt", "")
    lora_name = inp.get("lora_name", None) # ì˜ˆ: "my_style.safetensors"
    lora_scale = float(inp.get("lora_scale", 1.0))
    width = int(inp.get("width", 512))
    height = int(inp.get("height", 512))

    # ğŸ”¹ ë¡œë¼ ë™ì  ë¡œë“œ ë¡œì§
    if lora_name:
        lora_path = f"/workspace/loras/{lora_name}"
        
        # íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆì„ ë•Œë§Œ ë¡œë“œ
        if os.path.exists(lora_path):
            # ê¸°ì¡´ ë¡œë¼ê°€ ìˆë‹¤ë©´ í•´ì œí•˜ê³  ìƒˆë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
            pipe.unload_lora_weights() 
            pipe.load_lora_weights(lora_path)
        else:
            print(f"âš ï¸ ê²½ê³ : {lora_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì´ë¯¸ì§€ ìƒì„±
    with torch.inference_mode():
        image = pipe(
            prompt=prompt,
            num_inference_steps=int(inp.get("steps", 4)),
            guidance_scale=0.0,
            width=width,
            height=height,
            cross_attention_kwargs={"scale": lora_scale} if lora_name else {}
        ).images[0]

    # ì´ë¯¸ì§€ ë°˜í™˜
    buf = io.BytesIO()
    image.save(buf, format="PNG")
    return {"image": base64.b64encode(buf.getvalue()).decode("utf-8")}

runpod.serverless.start({"handler": handler})
