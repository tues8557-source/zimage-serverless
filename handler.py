import runpod
import torch
from diffusers import AutoPipelineForText2Image
import io
import base64
import os

# 1. ëª¨ë¸ ì„¤ì • (GPU ë©”ëª¨ë¦¬ì— ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ)
MODEL_ID = "stabilityai/sdxl-turbo"
pipe = AutoPipelineForText2Image.from_pretrained(
    MODEL_ID, 
    torch_dtype=torch.float16, 
    variant="fp16"
).to("cuda")

def handler(event):
    inp = event.get("input", {})
    action = inp.get("action", "generate") # ê¸°ë³¸ê°’ì€ ìƒì„±

    # ğŸ”¹ ë¡œë¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ìš”ì²­ì¸ ê²½ìš°
    if action == "list_loras":
        lora_dir = "/workspace/loras"
        if os.path.exists(lora_dir):
            files = [f for f in os.listdir(lora_dir) if f.endswith('.safetensors')]
            return {"lora_list": files}
        else:
            return {"lora_list": [], "error": "Folder not found"}
            
    # ğŸ”¹ ì…ë ¥ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    prompt = inp.get("prompt", "")
    lora_name = inp.get("lora_name", None)
    # lora_nameì´ "none" ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì²˜ë¦¬
    if lora_name == "none":
        lora_name = None
        
    lora_scale = float(inp.get("lora_scale", 1.0))
    width = int(inp.get("width", 512))
    height = int(inp.get("height", 512))
    steps = int(inp.get("steps", 4))

    # ğŸ”¹ ë¡œë¼ ë™ì  ë¡œë“œ ë¡œì§
    if lora_name:
        lora_path = f"/workspace/loras/{lora_name}"
        
        if os.path.exists(lora_path):
            print(f"DEBUG: [LoRA ì‹œì‘] íŒŒì¼ ë°œê²¬: {lora_path}")
            try:
                # 1) ì´ì „ ì‘ì—…ì˜ ë¡œë¼ê°€ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ˆê¸°í™”
                pipe.unload_lora_weights()
                
                # 2) ìƒˆë¡œìš´ ë¡œë¼ ê°€ì¤‘ì¹˜ ë¡œë“œ
                pipe.load_lora_weights(lora_path)
                print(f"DEBUG: [LoRA ì„±ê³µ] '{lora_name}' ë¡œë“œ ì™„ë£Œ (Scale: {lora_scale})")
            except Exception as e:
                print(f"DEBUG: [LoRA ì‹¤íŒ¨] ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                lora_name = None # ì‹¤íŒ¨ ì‹œ ë¡œë¼ ì ìš© ì œì™¸
        else:
            print(f"âš ï¸ DEBUG: [LoRA ì‹¤íŒ¨] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {lora_path}")
            lora_name = None
    else:
        # ë¡œë¼ ì´ë¦„ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œë¼ í•´ì œ í›„ ê¸°ë³¸ ëª¨ë¸ ìœ ì§€
        pipe.unload_lora_weights()
        print("DEBUG: ê¸°ë³¸ ëª¨ë¸(Base) ì‚¬ìš© ëª¨ë“œ")

    # ğŸ”¹ ì´ë¯¸ì§€ ìƒì„±
    try:
        with torch.inference_mode():
            # cross_attention_kwargsë¥¼ í†µí•´ ë¡œë¼ ê°•ë„ë¥¼ ì‹¤ì‹œê°„ ë°˜ì˜
            # ì´ ë°©ì‹ì€ ëª¨ë¸ì„ ì§ì ‘ ìˆ˜ì •(fuse)í•˜ì§€ ì•Šì•„ ì†ë„ê°€ ë¹ ë¥´ê³  ì•ˆì „í•©ë‹ˆë‹¤.
            image = pipe(
                prompt=prompt,
                num_inference_steps=steps,
                guidance_scale=0.0, # SDXL TurboëŠ” ëŒ€ê°œ 0.0 ì‚¬ìš©
                width=width,
                height=height,
                cross_attention_kwargs={"scale": lora_scale} if lora_name else {}
            ).images[0]

        # ì´ë¯¸ì§€ ë°˜í™˜ (Base64 ì¸ì½”ë”©)
        buf = io.BytesIO()
        image.save(buf, format="PNG")
        return {"image": base64.b64encode(buf.getvalue()).decode("utf-8")}

    except Exception as e:
        print(f"DEBUG: ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return {"error": str(e)}

# ì„œë²„ë¦¬ìŠ¤ ì‹œì‘
runpod.serverless.start({"handler": handler})
